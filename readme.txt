主要表结构：
item:商品表
item_stock:商品库存表
order_info:订单信息表
promo:秒杀信息表
sequence_info:序列信息表
user_info:用户信息表
user_password:用户密码表

其中将商品库存表分离出来：库存大量update操作，和item绑在一起的话，会产生相互竞争的行锁，影响数据库性能，将更新频繁的热数据分开，
也可以将冷数据分到新开的表中，这样每次数据库查询的时候，就会不需要load那么多的物理读。
也可以根据item做分库分表的操作,其中分表id可以是userid。

采用前后端分离架构，主要解决跨域问题：需要在ajax请求中添加 xhrFields：{withCredentials:true}解决session共享的问题，服务端支持跨域请求，在controller类上添加crossorigin。

全局异常处理：添加ControllerAdvice，需要判断传入异常类型。取消基类异常处理，解决404，405等异常

文件外挂配置：spring boot外挂配置文件 java -jar XX.jar  --spring.config.addition-location=  , 应用无状态配置

jmeter性能压测的主要配置：配置线程组，http请求，查看结果树，聚合报告。
通过pstree 查看进程下面的对应线程数，pstree -p 进程号，进程号的获取 ps -ef|grep java
top -h查看性能指标，主要是load average 1分钟 5分钟 15分钟的cpu load情况。一核就是1，超过1就是cpu被严重消耗。

spring boot 的server端并发数上不去，主要是内嵌的tomact默认配置有优化的地方，可以在spring-configuration-metadata.json查看可以在配置文件自定义参数。

一般4核，8g的机器tomact配置最优是
server.tomact.accept-count:等待队列长度默认是100，队列做缓冲池作用，但也不能无限长，消耗内存，出入队列也耗cpu，配置在1000.
server.tomact.max-connections：最大可被连接数默认10000
server.tomact.max-threads:最大工作线程数，默认200，最优配置是800-1000
server.tomact.min-space-threads:最小工作线程数，默认是10，最优是100

定制内嵌tomact开发，一般都是采用长连接的方式，但ddos会攻击，导致连接被沾满，需要控制长连接的时间和数量。
keepAliveTimeOut:多少毫秒后不响应的断开keepalive，
maxkeepAliverequests:多少次请求后keepalive断开失效
具体解决的办法：使用WebServerFactoryCustomizer<ConfigurableWebServerFactory>定制内嵌的tomact配置，将上面的两个参数配置

mysql数据库的qps容量问题，
主键查询：千万级别数据 = 1-10 毫秒 主要原因是聚簇索引
唯一索引查询：千万级别的数据=10-100毫秒
非唯一索引查询：千万级别的数据=100-1000毫秒
无索引：百万条数据=1000毫秒+

插入tps一般在1w-10w主要依赖于配置，不会产生行锁的竞争。

分布式会话管理，最好使用redis实现分布式会话存储

mysql数据库可以设置只有ip白名单在数据库mysql数据库中的user表中。
grant all privileges on *.* to root@'%' indentified by 'root' 对于所有知道root密码的用户都可以登录数据库。把权限全部到flush进去。

nginx在互联网中主要的作用是web服务器，动静分离服务器，反向代理服务器。

一般采用nas网盘，挂载在本地。因为nas是无限大的。
nginx中关键字alias是替换的作用，upstream是真正后端的代理，nginx需要将必要的信息全部传输到后端tomact，比如ip地址，不然就是nginx的地址。
再生产还是要将access_log开启，server.tomact.accesslog.enables=true,server.tomact.accesslog.directory= server.tomact.accessloglog.pattern=%h %l %u

tomact的日志时异步刷新的，所以对性能影响较小，log4j2在内部采用了disruptor无锁的队列

nginx和后端的tomact默认是短连接的状态，是没有keepalive的，减少连接建联之间的消耗

修改nginx配置，在upstream配置中，keepalive 30

前端和nginx是长连接，在nginx中配置，nginx和后端tomact是长连接，tomact和数据库采用druid数据源，也是长连接。

nginx高性能的原因

epoll多路复用：master worker进程模型，可以平滑的重启，
协程协议：一个线程可以有多个协程，协程切换不会引起cpu的切换，只是内存的切换，协程只是线程的内存模型。协程遇到阻塞的时候（socket.read），会交出执行权,找到不阻塞的协程，是同步的。

协程是线性执行，不需要加锁。

linux 2.6以上实际是epoll模型，只是函数名叫select

父进程可以管理子进程，父进程可以访问子进程几乎所有的变量。

nginx -s reload master的进程号不会变，但worker会变，master首先拿到所有的连接，句柄，然后加载配置文件，然后创建新的worker进程，再将连接句柄交给新的worker进程，

多线程就是为了防止多io的操作。

lua也是采用协程的机制

redis是分布式会话的不二人选，

&后台启动

在最新版本的h5中，window.localstorge存储对应的token，内存更大，

将缓存推到离用户最近地方，用户访问的链路就越少，但会有脏缓存清理，可以采用lru算法和storm实时统计，进行反向更新数据。

哨兵机制 的分片是客户端做，比如hash，如果是添加机器需要数据迁移，很复杂。容易产生脑裂，断链

cluster的部署都是在redis集群中控制，当有机器删除或者上线，会重新hash，boot已经帮我么继承了spring-data-redis集成

多级缓存的作用：nginx+lua的缓存主要作用是热点，爆点数据，redis缓存，容量大，主要是提高qps，本地缓存数据主要是防止出现redis雪崩，打到数据库，还可以用零散的本地缓存数据，抗住部分的流量，主redis集群的作用是防止主从之间的数据延迟。

本地热点缓存：热点数据，脏读不敏感，内存可控(存活时间)，采用guava cache
本地缓存qps相对于redis的1.5倍，减少网络的开销
缺点是，当数据更新的时候，没有好的办法去更新

nginx proxy cache 缓存：nginx反向代理前置，依靠文件系统存索引级的文件。依靠内存缓存文件地址。内存存的是key，value是在磁盘上。性能较差
nginx+lua原理
lua协程机制：线程工作区间内的一个单元，类似线程一样有自己的单元，依托于线程，被cpu执行，编写代码的时候，不需要考虑异步，直接同步，只要遇到阻塞，直接交出执行权。串行执行，无需加锁

cname的作用类似dns，www.baidu.com访问这个地址时，首先访问dns，然后dns发现是cname地址，然后将地址发送到cname地址，阿里云会解析出来发送过来的地址，就会根据访问者的ip地址，会就近选择一个cdn节点让用户访问这个节点地址，cdn然后判断本地缓存是有对应的静态资源地址，如果没有则回源到我们的工程地址(会在阿里云配置)，拉取资源文件。

http的cache control 服务端告诉客户端是否可以存储。

几个类型
private：客户端可以缓存，
public：客户端和代理服务器都可以缓存
max-age=XX:缓存在多少秒后失效
no-cache：强制向服务端再验证一次，用的时候去服务端ask一次，
   etag：资源唯一(md5)标示，第一次返回给浏览器，浏览器会存储，有效性校验就是，浏览器发送一次请求呆着etag到服务端和服务端的资源文件的etag进行比较，要是一样的返回304.
  if-none-match；客户端发送的匹配etag标识符
  last-modified：资源最后背修改的时间，
no-store:不缓存

浏览器的刷新方式
动态请求，都是no-cache，没有max-age，没有etag，压根没有协商

http缓存基础知识
报文信息主要分为两部分
1.包含属性的首部(header)--------------------------附加信息（cookie，缓存信息等）与缓存相关的规则信息，均包含在header中
2.包含数据的主体部分(body)-----------------------HTTP请求真正想要传输的部分
缓存规则解析
为方便大家理解，我们认为浏览器存在一个缓存数据库,用于存储缓存信息。
在客户端第一次请求数据时，此时缓存数据库中没有对应的缓存数据，需要请求服务器，服务器返回后，将数据存储至缓存数据库中。

HTTP缓存有多种规则，根据是否需要重新向服务器发起请求来分类，分为两大类(强制缓存，对比缓存).
已存在缓存数据时，仅基于强制缓存，请求数据的流程如下


已存在缓存数据时，仅基于对比缓存，请求数据的流程如下

我们可以看到两类缓存规则的不同，强制缓存如果生效，不需要再和服务器发生交互，而对比缓存不管是否生效，都需要与服务端发生交互。
两类缓存规则可以同时存在，强制缓存优先级高于对比缓存，也就是说，当执行强制缓存的规则时，如果缓存生效，直接使用缓存，不再执行对比缓存规则。


可见协商缓存无论如何都会和服务器交互，比较强缓存稍微要复杂一点，但是二者是相辅相成并且可以共同存在的，强缓存优先级较高，意味着请求一个资源时会先比较强缓存的字段，如果命中则不会再执行接下来的协商缓存的过程。
2.协商缓存
协商缓存是通过客户端和服务端进行HTTP通信时，所在响应头和请求头中互相表达“暧昧”的，相互通气，互送缓存标识。

Last-Modified 和 If-Modified-Since

第一次请求某一个资源时，由于一定不会走缓存，所以服务器端会在资源的响应头中加上一个形如Last-Modified:Mon, 26 Feb 2018 06:37:41 GMT的字段告诉客户端浏览器，这个资源上次最后修改的时间；刷新页面再次请求，这时候的协商缓存会在请求头中加上一个形如If-Modified-Since:Mon, 26 Feb 2018 06:37:41 GMT，字面翻译就是，是否在上个“暧昧”时间后修改了，值毫无疑问是服务端上一次响应给他的时间，让服务器去判断是否在此时间之后资源内容发生了变化。
整个过程也很简单，最后的结果也很简短。如果服务端发现改变了资源，就伴着200的 statuscode 和新鲜的资源给到客户端，若是没有修改，304 Not Modified让客户端从缓存中取。

Etag 和 If-None-Match

同样，第一次客户端请求一个资源文件时，服务端随资源在响应头部中甩来一个字段 Etag ，形如ETag:W/"1823823287"该字段的值是该资源在服务器端的唯一标识，生成的Etag值的策略有服务端决定，总之是资源的一个唯一的标识。资源发生变化则该值也发生变化。下一次客户端请求同一个资源的时候，在请求头将这次得到的值放在请求头中一个叫 If-None-Match 的字段中甩给服务端。
整个过程也很简单，最后的结果也很简短。如果服务端发现改变了资源，就伴着200的 statuscode 和新鲜的资源给到客户端，若是没有修改，304 Not Modified让客户端从缓存中取。
上述两个方式中，Etag 和 If-None-Match的优先级要高于Last-Modified 和 If-Modified-Since，进而会衍生出一个思考，二者相比功能相同，但是表达形式决定了 Etag 解决了 Last-Modified 存在的一些问题，比如Last-Modified 是比较时间，精确到秒，若是毫秒级的改变则没法兼顾，存在着周期性更改的资源，然而有可能资源本身的内容并没有改变，那如果重新请求响应意义并不是那么的大。所以不难理解Etag具有高优先级有他的合理之处。



cdn自定义缓存策略
可以自定义目录过期时间
可定义后缀名过期时间
可自定义对应权重
强制刷新

静态资源部署策略
1.加版本号，因为资源文件都是在html中引入的，因此html都是需要no-cache的，要求每次都是去服务端进行校验一次。但这很不方便
2.资源文件使用摘要做文件名部署，例如45ree.js，新老版本并存且回滚，资源部署完后再部署html。这种方案最好。

交易优化技术之缓存库存
性能影响点：交易验证完全依赖数据库，库存行锁(串行)，后置处理逻辑

交易验证优化
用户风控策略模型：策略缓存模型化
活动校验策略优化:引入活动发布流程，模型缓存华，紧急下线能力。

库存行级优化
 扣减库存缓存化
 异步同步数据库
 保证数据最终一致性

异步消息进行缓存库存异步化。

数据类型：

主业务数据：master data
操作性数据：log data

设计原则：宁可少卖，不能超卖
   redis可以比数据库少，超时释放(15分钟未收到订单成功还是失败，需要释放商品数)，

一般不会异步下单，会采取异步同步库存模型，首先落单，记录核心数据，如果不记录数据，则用户来查询的时候可能查不到。

流量削峰技术

秒杀令牌：
    秒杀下单接口会被不停的狂刷
    秒杀验证逻辑和秒杀下单接口强关联，代码冗余度高
    秒杀验证逻辑复杂，对交易系统产生无关联负载(交易，生成交易单，扣减库存)
    但秒杀令牌只要活动一开始就无限制生成，影响系统性能，因此需要秒杀大闸
秒杀大闸
   依靠秒杀令牌的授权原理定制化发牌逻辑，做到大闸功能
   根据秒杀商品初始存库颁发对应数量令牌，控制大闸流量
   将用户风控策略前置到秒杀令牌发放中
   库存售罄前置到秒杀令牌发放中
   发放5倍的令牌
   但浪涌流量涌入后系统无法应对，多库存，多商品等令牌限制能力弱，因此需要队列泄洪
队列泄洪
   排队比并发更高效，例如redis，innodb。上线文切换，cpu切换，内存空间切换。
   依靠排队去限制并发流量
   依靠排队和下游拥塞窗口程度调整队列释放流量大小，
   支付宝银行网关队列举例，ZQ。
   本地还是分布式，强烈使用内存队列，但可能会有分配不均匀问题。可以由分布式队列降级为本地队列
           本地：维护在内存中，没有网络问题。
           分布式：性能问题。


秒杀令牌原理:
秒杀接口需要依靠令牌才能进入，
秒杀的令牌由秒杀活动模块负责生成
秒杀活动模块对秒杀令牌生成全权负责，逻辑收口
秒杀下单前需要先获取秒杀令牌


验证码生成和验证技术
  包装秒杀令牌前置，需要验证码来错峰
  数学公式验证码生成器
限流原理和实现
  流量远比你想的更多
  系统或者总比挂了要好
  宁愿少数人能用，也不要所有人能用
    限流方案
        限并发(全局计数器，servlet-1,处理完+1)
        限制qps和tps，令牌桶算法和漏桶算法。
   令牌桶算法:应对突发的流量，互联网用的多，维度：接口维度，总维度(相比接口限流总和少2成)。
     限流范围：集群限流，redis，会产生性能瓶颈。单机限流，负载均衡的前提是单机平均限流效果更好。
  大部分情况下都是采用单机限流。
guava limit模块

   漏桶算法:无法处理突发的流量

防黄牛技术

kafka的性能要比rocketmq要好，redis之间的数据同步是通过kafka进行传输，tps最高50w。
























































